{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cxWu8W2ba9l"
   },
   "source": [
    "# LSTM\n",
    "\n",
    "Here we do the sentiment analysis of the IMDB data set using a simple LSTM (Long Short-Term Memory).\n",
    "\n",
    "LSTM has a good proven record when we are working with long sequential data and here as well we have a sequential text data with us. So, it might be a good idea using LSTM for it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yPBxl3U2qy5y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD9iIEN8d9yW"
   },
   "source": [
    "# Data Downloading\n",
    "\n",
    "Here we simply download the data and put it into a tensorflow data set at the beginning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5Pdk3zWr_0u",
    "outputId": "0ea54fc9-a403-43c1-9fd4-25c139fcec77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-07 18:16:12--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar.gz.4’\n",
      "\n",
      "aclImdb_v1.tar.gz.4 100%[===================>]  80.23M  29.6MB/s    in 2.7s    \n",
      "\n",
      "2021-12-07 18:16:15 (29.6 MB/s) - ‘aclImdb_v1.tar.gz.4’ saved [84125825/84125825]\n",
      "\n",
      "aclImdb\t\t   aclImdb_v1.tar.gz.1\taclImdb_v1.tar.gz.3  sample_data\n",
      "aclImdb_v1.tar.gz  aclImdb_v1.tar.gz.2\taclImdb_v1.tar.gz.4\n"
     ]
    }
   ],
   "source": [
    "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xzf aclImdb_v1.tar.gz\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9WsRgohtsFfu"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H9RWj1ENsHXU"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w2gmDfaDsI8h"
   },
   "outputs": [],
   "source": [
    "(ds_train,ds_test),ds_info = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=[\"train\",\"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r27n8at4DJ5L"
   },
   "source": [
    "# Steps for implementation:\n",
    "\n",
    "1 Data processing: cleaning the data, removing stopwords, splitting into X_test, y_test, X_train, y_train and Finally, Calculating maxlen for encoding\n",
    "\n",
    "2 Tokenization and encoding: Tokenization and encoding X_train and X_test\n",
    "\n",
    "3 LSTM modelling: LSTM model and Bidirectional LSTM\n",
    "\n",
    "PS: different explained and detail in comments. When implementing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej0S6XyoeZkR"
   },
   "source": [
    "# Data processing.\n",
    "\n",
    "Here we firstly convert the data into a dataframe since it is easier to deal with in a data frame. Then post that we clean the data and make it comatible for our further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LPUOhzNHsKpM"
   },
   "outputs": [],
   "source": [
    "# we create a dataframe from a tensorflow data object\n",
    "#we take a higher value than 25000 in take() so that we do not miss any values\n",
    "ds_train = tfds.as_dataframe(ds_train.take(25100), ds_info)\n",
    "ds_test = tfds.as_dataframe(ds_test.take(25100), ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qUQv2ofCsaRp",
    "outputId": "6e4baacd-56d5-4f99-a339-3788d04e4e3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"This was an absolutely terrible movie. Don't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'I have been known to fall asleep during film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Mann photographs the Alberta Rocky Mountains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b'This is the kind of film for a snowy Sunday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>b'As others have mentioned, all the women that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  b\"This was an absolutely terrible movie. Don't...\n",
       "1      0  b'I have been known to fall asleep during film...\n",
       "2      0  b'Mann photographs the Alberta Rocky Mountains...\n",
       "3      1  b'This is the kind of film for a snowy Sunday ...\n",
       "4      1  b'As others have mentioned, all the women that..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.head(5)\n",
    "#we see these b's as data converts to bytes hence we need to decode the bytes and do some basic cleaning to the data set\n",
    "# its probably because of utf 8, the data is not easy to deal with if it is in the byte format for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rBomG41luQvN",
    "outputId": "7bf46d21-4b75-421d-fee3-c1d409850dc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this was an absolutely terrible movie dont be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i have been known to fall asleep during films ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mann photographs the alberta rocky mountains i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>this is the kind of film for a snowy sunday af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>as others have mentioned all the women that go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  this was an absolutely terrible movie dont be ...\n",
       "1      0  i have been known to fall asleep during films ...\n",
       "2      0  mann photographs the alberta rocky mountains i...\n",
       "3      1  this is the kind of film for a snowy sunday af...\n",
       "4      1  as others have mentioned all the women that go..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we can see their are some weird characters in between, lets do the very basic cleaning\n",
    "def basic_clean(txt):\n",
    "  txt = txt.decode(\"utf-8\") #to remove b's from the beginning of the text and make it string\n",
    "  txt = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\").sub(\"\", txt.lower()) #remove punctuations change and text to lower case\n",
    "  txt = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\").sub(\" \", txt.lower()) #remove links since we want to do textual analysis\n",
    "  return txt\n",
    "ds_train['text'] =  ds_train['text'].apply(basic_clean) #apply the above function to train part of data set\n",
    "ds_test['text'] =  ds_test['text'].apply(basic_clean) #apply the above function to test part of data set\n",
    "ds_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "uuojhusqhtDd",
    "outputId": "0c69bf52-a62a-4adc-f39f-dba08995d4ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this was an absolutely terrible movie dont be lured in by christopher walken or michael ironside both are great actors but this must simply be their worst role in history even their great acting could not redeem this movies ridiculous storyline this movie is an early nineties us propaganda piece the most pathetic scenes were those when the columbian rebels were making their cases for revolutions maria conchita alonso appeared phony and her pseudo love affair with walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning i am disappointed that there are movies like this ruining actors like christopher walkens good name i could barely sit through it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i have been known to fall asleep during films but this is usually due to a combination of things including really tired being warm and comfortable on the sette and having just eaten a lot however on this occasion i fell asleep because the film was rubbish the plot development was constant constantly slow and boring things seemed to happen but with no explanation of what was causing them or why i admit i may have missed part of the film but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else i cant recommend this film at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mann photographs the alberta rocky mountains in a superb fashion and jimmy stewart and walter brennan give enjoyable performances as they always seem to do  but come on hollywood   a mountie telling the people of dawson city yukon to elect themselves a marshal yes a marshal and to enforce the law themselves then gunfighters battling it out on the streets for control of the town  nothing even remotely resembling that happened on the canadian side of the border during the klondike gold rush mr mann and company appear to have mistaken dawson city for deadwood the canadian north for the american wild west canadian viewers be prepared for a reefer madness type of enjoyable howl with this ludicrous plot or to shake your head in disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>this is the kind of film for a snowy sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm chair and mellow for a couple of hours wonderful performances from cher and nicolas cage as always gently row the plot along there are no rapids to cross no dangerous waters just a warm and witty paddle through new york life at its best a family film in every sense and one that deserves the praise it received</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>as others have mentioned all the women that go nude in this film are mostly absolutely gorgeous the plot very ably shows the hypocrisy of the female libido when men are around they want to be pursued but when no men are around they become the pursuers of a 14 year old boy and the boy becomes a man really fast we should all be so lucky at this age he then gets up the courage to pursue his true love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>this is a film which should be seen by anybody interested in effected by or suffering from an eating disorder it is an amazingly accurate and sensitive portrayal of bulimia in a teenage girl its causes and its symptoms the girl is played by one of the most brilliant young actresses working in cinema today alison lohman who was later so spectacular in where the truth lies i would recommend that this film be shown in all schools as you will never see a better on this subject alison lohman is absolutely outstanding and one marvels at her ability to convey the anguish of a girl suffering from this compulsive disorder if barometers tell us the air pressure alison lohman tells us the emotional pressure with the same degree of accuracy her emotional range is so precise each scene could be measured microscopically for its gradations of trauma on a scale of rising hysteria and desperation which reaches unbearable intensity mare winningham is the perfect choice to play her mother and does so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>okay you have penelope keith as miss herringbone tweed bbe backbone of england shes killed off in the first scene   thats right folks this show has no backbone peter otoole as ol colonel cricket from the first war and now the emblazered lord of the manor joanna lumley as the ensweatered lady of the manor 20 years younger than the colonel and 20 years past her own prime but still glamourous brit spelling not mine enough to have a toy boy on the side its alright they have col crickets full knowledge and consent they guy even comes round for christmas still shes considerate of the colonel enough to have said toy boy her own age what a gal david mccallum as said toy boy equally as pointlessly glamourous as his squeeze pilcher couldnt come up with any cover for him within the story so she gave him a hush hush job at the circus and finally susan hampshire as miss polonia teacups venerable headmistress of the venerable girls boarding school serving tea in her office with a dash of deep po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>the film is based on a genuine 1950s novel journalist colin mcinnes wrote a set of three london novels absolute beginners city of spades and mr love and justice i have read all three the first two are excellent the last perhaps an experiment that did not come off but mcinness work is highly acclaimed and rightly so this musical is the novelists ultimate nightmare   to see the fruits of ones mind being turned into a glitzy badly acted soporific one dimensional apology of a film that says it captures the spirit of 1950s london and does nothing of the sort thank goodness colin mcinnes wasnt alive to witness it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>i really love the sexy action and sci fi films of the sixties and its because of the actresss that appeared in them they found the sexiest women to be in these films and it didnt matter if they could act remember candy the reason i was disappointed by this film was because it wasnt nostalgic enough the story here has a european sci fi film called dragonfly being made and the director is fired so the producers decide to let a young aspiring filmmaker jeremy davies to complete the picture theyre is one real beautiful woman in the film who plays dragonfly but shes barely in it film is written and directed by roman coppola who uses some of his fathers exploits from his early days and puts it into the script i wish the film could have been an homage to those early films they could have lots of cameos by actors who appeared in them there is one actor in this film who was popular from the sixties and its john phillip law barbarella gerard depardieu giancarlo giannini and dean stockwell ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>sure this one isnt really a blockbuster nor does it target such a position dieter is the first name of a quite popular german musician who is either loved or hated for his kind of acting and thats exactly what this movie is about it is based on the autobiography dieter bohlen wrote a few years ago but isnt meant to be accurate on that the movie is filled with some sexual offensive content at least for american standard which is either amusing not for the other actors of course or dumb   it depends on your individual kind of humor or on you being a bohlen fan or not technically speaking there isnt much to criticize speaking of me i find this movie to be an ok movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text\n",
       "0      0                                                                                                                                                                                                                                                                                                                    this was an absolutely terrible movie dont be lured in by christopher walken or michael ironside both are great actors but this must simply be their worst role in history even their great acting could not redeem this movies ridiculous storyline this movie is an early nineties us propaganda piece the most pathetic scenes were those when the columbian rebels were making their cases for revolutions maria conchita alonso appeared phony and her pseudo love affair with walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning i am disappointed that there are movies like this ruining actors like christopher walkens good name i could barely sit through it\n",
       "1      0                                                                                                                                                                                                                                                                                                                                                                                                             i have been known to fall asleep during films but this is usually due to a combination of things including really tired being warm and comfortable on the sette and having just eaten a lot however on this occasion i fell asleep because the film was rubbish the plot development was constant constantly slow and boring things seemed to happen but with no explanation of what was causing them or why i admit i may have missed part of the film but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else i cant recommend this film at all\n",
       "2      0                                                                                                                                                                                                                                                                      mann photographs the alberta rocky mountains in a superb fashion and jimmy stewart and walter brennan give enjoyable performances as they always seem to do  but come on hollywood   a mountie telling the people of dawson city yukon to elect themselves a marshal yes a marshal and to enforce the law themselves then gunfighters battling it out on the streets for control of the town  nothing even remotely resembling that happened on the canadian side of the border during the klondike gold rush mr mann and company appear to have mistaken dawson city for deadwood the canadian north for the american wild west canadian viewers be prepared for a reefer madness type of enjoyable howl with this ludicrous plot or to shake your head in disgust\n",
       "3      1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 this is the kind of film for a snowy sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm chair and mellow for a couple of hours wonderful performances from cher and nicolas cage as always gently row the plot along there are no rapids to cross no dangerous waters just a warm and witty paddle through new york life at its best a family film in every sense and one that deserves the praise it received\n",
       "4      1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         as others have mentioned all the women that go nude in this film are mostly absolutely gorgeous the plot very ably shows the hypocrisy of the female libido when men are around they want to be pursued but when no men are around they become the pursuers of a 14 year old boy and the boy becomes a man really fast we should all be so lucky at this age he then gets up the courage to pursue his true love\n",
       "5      1  this is a film which should be seen by anybody interested in effected by or suffering from an eating disorder it is an amazingly accurate and sensitive portrayal of bulimia in a teenage girl its causes and its symptoms the girl is played by one of the most brilliant young actresses working in cinema today alison lohman who was later so spectacular in where the truth lies i would recommend that this film be shown in all schools as you will never see a better on this subject alison lohman is absolutely outstanding and one marvels at her ability to convey the anguish of a girl suffering from this compulsive disorder if barometers tell us the air pressure alison lohman tells us the emotional pressure with the same degree of accuracy her emotional range is so precise each scene could be measured microscopically for its gradations of trauma on a scale of rising hysteria and desperation which reaches unbearable intensity mare winningham is the perfect choice to play her mother and does so...\n",
       "6      0  okay you have penelope keith as miss herringbone tweed bbe backbone of england shes killed off in the first scene   thats right folks this show has no backbone peter otoole as ol colonel cricket from the first war and now the emblazered lord of the manor joanna lumley as the ensweatered lady of the manor 20 years younger than the colonel and 20 years past her own prime but still glamourous brit spelling not mine enough to have a toy boy on the side its alright they have col crickets full knowledge and consent they guy even comes round for christmas still shes considerate of the colonel enough to have said toy boy her own age what a gal david mccallum as said toy boy equally as pointlessly glamourous as his squeeze pilcher couldnt come up with any cover for him within the story so she gave him a hush hush job at the circus and finally susan hampshire as miss polonia teacups venerable headmistress of the venerable girls boarding school serving tea in her office with a dash of deep po...\n",
       "7      0                                                                                                                                                                                                                                                                                                                                                                                                   the film is based on a genuine 1950s novel journalist colin mcinnes wrote a set of three london novels absolute beginners city of spades and mr love and justice i have read all three the first two are excellent the last perhaps an experiment that did not come off but mcinness work is highly acclaimed and rightly so this musical is the novelists ultimate nightmare   to see the fruits of ones mind being turned into a glitzy badly acted soporific one dimensional apology of a film that says it captures the spirit of 1950s london and does nothing of the sort thank goodness colin mcinnes wasnt alive to witness it\n",
       "8      0  i really love the sexy action and sci fi films of the sixties and its because of the actresss that appeared in them they found the sexiest women to be in these films and it didnt matter if they could act remember candy the reason i was disappointed by this film was because it wasnt nostalgic enough the story here has a european sci fi film called dragonfly being made and the director is fired so the producers decide to let a young aspiring filmmaker jeremy davies to complete the picture theyre is one real beautiful woman in the film who plays dragonfly but shes barely in it film is written and directed by roman coppola who uses some of his fathers exploits from his early days and puts it into the script i wish the film could have been an homage to those early films they could have lots of cameos by actors who appeared in them there is one actor in this film who was popular from the sixties and its john phillip law barbarella gerard depardieu giancarlo giannini and dean stockwell ap...\n",
       "9      0                                                                                                                                                                                                                                                                                                                                         sure this one isnt really a blockbuster nor does it target such a position dieter is the first name of a quite popular german musician who is either loved or hated for his kind of acting and thats exactly what this movie is about it is based on the autobiography dieter bohlen wrote a few years ago but isnt meant to be accurate on that the movie is filled with some sexual offensive content at least for american standard which is either amusing not for the other actors of course or dumb   it depends on your individual kind of humor or on you being a bohlen fan or not technically speaking there isnt much to criticize speaking of me i find this movie to be an ok movie"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000) #to view more of data in the data frame\n",
    "ds_train.head(10) #check the application of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XboBQQNzskMJ"
   },
   "outputs": [],
   "source": [
    "#split the data into X_train, y_train, X_test, y_test\n",
    "X_train = ds_train['text']\n",
    "y_train = ds_train['label']\n",
    "X_test = ds_test['text']\n",
    "y_test = ds_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzOnmrIYsfn7",
    "outputId": "f0e01c23-6d7e-4c59-c94e-8f7be87b2185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#remove stopwords from test and train. We remove stopwords because since these words occour a lot and don't add much meaning to the sentences\n",
    "nltk.download('stopwords')\n",
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tojyyOVruC7R"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.replace({'[^A-Za-z]': ' '}, regex = True) #remove non alphabet for textual analysis\n",
    "X_test = X_test.apply(lambda text: [w for w in text.split() if w not in english_stops])  #remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SyjuR1jCtg74"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.replace({'[^A-Za-z]': ' '}, regex = True)     #remove non alphabet for textual analysis\n",
    "X_train = X_train.apply(lambda text: [w for w in text.split() if w not in english_stops])  # remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "t93iAt2eumZA"
   },
   "outputs": [],
   "source": [
    "#function to max_len for texts_to_sequences\n",
    "def get_maxlen():\n",
    "    review_len = []\n",
    "    for txt in X_train:\n",
    "        review_len.append(len(txt))\n",
    "    return int(np.ceil(np.mean(review_len)))\n",
    "    #we use the mean value of the lengths of the texts in the data\n",
    "    #mean is a bit higher than the meidan as median is 90 and mean is 122 hence i went with mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiyuM-lr3htE"
   },
   "source": [
    "# Tokenization and Encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcyFe_7lvPGw",
    "outputId": "37a21af2-fcde-4cb2-b7f5-060faa75e308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[  312   284     1 ...     0     0     0]\n",
      " [  451   674  2211 ...     0     0     0]\n",
      " [ 4198  5932 26692 ...     0     0     0]\n",
      " ...\n",
      " [  750    90    53 ...  4587   475  1171]\n",
      " [  116  1333   138 ...     0     0     0]\n",
      " [   18 16630   276 ...   294     7  4731]] \n",
      "\n",
      "Encoded X Test\n",
      " [[   25    23  3887 ...     0     0     0]\n",
      " [36686   571   662 ...     3 19996   603]\n",
      " [  504     1  1547 ...   111 20541   176]\n",
      " ...\n",
      " [28021     1   103 ...     0     0     0]\n",
      " [  492   745  8648 ...     0     0     0]\n",
      " [   20    23  2263 ...     0     0     0]] \n",
      "\n",
      "Maximum review length:  122\n"
     ]
    }
   ],
   "source": [
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(X_train) #we fit it on train data it creates tokens using train data as its corpus\n",
    "X_train = token.texts_to_sequences(X_train) #it creates sequences using the tokens from the above fit_on_texts\n",
    "X_test = token.texts_to_sequences(X_test) #it uses the same tokens from the train part to create its sequences and removes the words from the sequence which are unique to test data\n",
    "\n",
    "max_length = get_maxlen() #it is the maximum length sentence for the analysis\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post') #encoded x train, this makes the sequence of a fixed length of max len and truncates the sequence if its longer than max len and if it shorter it provides the sequence padding to make sequence of uniform max len\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post') #encoded x test, it does the same to test data\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', X_train, '\\n')\n",
    "print('Encoded X Test\\n', X_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj_8YR0f3z5T"
   },
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDCokEr7vgPV",
    "outputId": "ce191c4a-6810-4c6a-e7dd-3056c1bdbe07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 122, 32)           2888800   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,897,153\n",
      "Trainable params: 2,897,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 32\n",
    "LSTM_1 = 32 #number of lstm cells\n",
    "from keras import backend as K\n",
    "K.clear_session() #clear the tensor\n",
    "#model\n",
    "model = Sequential() #instantiate the model\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length)) #embedding input dimension is total number of words/size of vocabulary and output dimension is EMBED_DIM and input length is the max_length of sequence, we defined before while encoding the train and test\n",
    "#we use an embedding layer \n",
    "model.add(LSTM(LSTM_1)) #lstm \n",
    "model.add(Dense(1, activation='sigmoid')) #since binary output we use dense 1 and sigmoid as activation\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy']) #we use binary_crossentropy because of the type of output metric as accuracy since the data set is balanced in negative and positive reviews and we settle on rms prop as optimizer beacuse it gave the best result compared to others\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6hVZ_7RvskW",
    "outputId": "50493389-25d9-410d-de18-788a7a84c047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 57s 70ms/step - loss: 0.4593 - accuracy: 0.7694\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 54s 69ms/step - loss: 0.2662 - accuracy: 0.9000\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 54s 70ms/step - loss: 0.2065 - accuracy: 0.9270\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 55s 70ms/step - loss: 0.1767 - accuracy: 0.9409\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 54s 69ms/step - loss: 0.1529 - accuracy: 0.9504\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 32, epochs = 5)\n",
    "#LSTM overfits quite quickly hence we run less epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u932H-DCwEv9",
    "outputId": "d88a153c-279b-43c2-efcb-14d952a28dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 13ms/step - loss: 0.4170 - accuracy: 0.8403\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2pPzT0qxBjB",
    "outputId": "c0aff751-515f-451e-d2b5-3964f8ff20a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8533999919891357\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb4rwgSZFiF2"
   },
   "source": [
    "# Bidirectional LSTM\n",
    "\n",
    "Bidirectional models try to understand the context of the sentence from left to right and right to left and later concatenate it. Which makes a worthwhile approach to try in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoxSQTfY0rFF",
    "outputId": "8b7a9bad-f964-4d2d-febd-c8cdb2ed5c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 122, 32)           2888800   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 122, 32)          6272      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 32)               6272      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,901,377\n",
      "Trainable params: 2,901,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "EMBED_DIM = 32\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential() #instantiate the model\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))  #embedding input dimension is total number of words/size of vocabulary and output dimension is EMBED_DIM and input length is the max_length of sequence, we defined before while encoding the train and test\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True))) #Bidirectional Layer\n",
    "model.add(Bidirectional(LSTM(16))) #bidirectional later\n",
    "model.add(Dense(1, activation='sigmoid')) #since binary output we use dense 1 and sigmoid as activation\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])  #we use binary_crossentropy because of the type of output metric as accuracy since the data set is balanced in negative and positive reviews and we settle on rms prop as optimizer beacuse it gave the best result compared to others\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8vSx1GRnwLo",
    "outputId": "3c4bd5f4-785d-444d-cd6e-07cbea1da55b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 136s 164ms/step - loss: 0.3873 - accuracy: 0.8244\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 128s 164ms/step - loss: 0.2279 - accuracy: 0.9133\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 130s 167ms/step - loss: 0.1783 - accuracy: 0.9360\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 32, epochs = 3)\n",
    "#LSTM overfits quite quickly hence we run less epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcFOJmdioSNX",
    "outputId": "515150b2-f24c-4879-fc27-584599a8e062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 24s 30ms/step - loss: 0.3630 - accuracy: 0.8561\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcBMoFzLqyt9",
    "outputId": "0f102853-1ce7-4949-fc32-0a221976741a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy Bidirectional: 0.8561199903488159\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy Bidirectional:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7q8NOvDsbJu"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "LSTM gives a decent accuracy but overfits quite easily if we give high number of epochs in case of both standard LSTM and bidirectional LSTM.\n",
    "\n",
    "Bidirectional LSTM (85.6) has almost at the same level of accuracy on test set as the standard LSTM (85.3) since it with 2 epochs. Probably bidirectional LSTM understands the cotext much quicker than a standard LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApLVl83qP9lG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final IMDB_LSTM_Naman",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
